{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b5871f5",
   "metadata": {},
   "source": [
    "\n",
    "# 视野预测可解释性工具（融合层 / 骨干 / Patch-PCA）— 中文版\n",
    "\n",
    "本 Notebook 统一在顶部集中**配置**，并提供三类可视化：  \n",
    "1. **融合层可解释性**：`gated-sum` 的门控 `g`、`attn` 的 2x2 注意力；  \n",
    "2. **骨干（ViT）可解释性**：Attention Rollout 与 CLS→patch 显著图；  \n",
    "3. **Patch 级 PCA**：对 rnflt 与 slab 使用**共享 PCA 空间**，用于“模态互补”论证。\n",
    "\n",
    "> 说明：请将 `配置区` 中的路径改为你本机环境；模型与数据加载逻辑按你的训练脚本对齐。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da76926b",
   "metadata": {},
   "source": [
    "## 0. 配置区（请按需修改）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13380e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/sda/sijiali/anaconda3/envs/glaucoma/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ====== 全局配置（集中写在这里）======\n",
    "import os, math, warnings, types, json, random\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image, ImageFilter\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "from utils import get_vit_transform, get_cnn_transform, get_albumentations_transform, get_imagenet_transform\n",
    "from train import get_dataloader_Salsa, SalsaHGFAlignedDataset\n",
    "from dino_model import DualDinoV3LateFusion52  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd726919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "配置完成。\n"
     ]
    }
   ],
   "source": [
    "# 设备\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# 路径与超参（与训练脚本保持一致）\n",
    "CFG = dict(\n",
    "    \n",
    "    # model\n",
    "    backbone      = \"dinov3\",                                 # 仅支持 dinov3\n",
    "    dinov3_model  = \"/mnt/sda/sijiali/GlaucomaCode/pretrained_weight/dinov3-vitb16-pretrain-lvd1689m\",\n",
    "    fusion        = \"concat\",                                  # \"concat\" / \"gated-sum\" / \"sum\" / \"attn\"\n",
    "    vit_pool      = \"cls\",                                     # \"cls\" 或 \"mean_patch\"\n",
    "    train_scope   = \"all\",                                    # \"head\" 或 \"all\"（只影响加载后是否冻结，不影响可视化）\n",
    "    ckpt_path     = \"/mnt/sda/sijiali/GlaucomaCode/Results_SALSA_multi/dinov3/dinov3_imagenet_all_cls_concat_lr5e-5/ckpts/best_model_epoch_302_rmse_1.0466.pth\",   # 可视化的最优权重\n",
    "    \n",
    "    # data\n",
    "    transform     = \"imagenet\",                                # \"vit\"/\"cnn\"/\"albumentations\"/\"none\"/\"imagenet\"\n",
    "    modality_type = \"rnflt+slab\",                              # \"rnflt\" 或 \"rnflt+slab\"\n",
    "    img_size      = 224,                                       # 输入尺寸\n",
    "    data_root     = \"/mnt/sda/sijiali/DataSet/harvardGF_unpacked\",\n",
    "    hgf_test_root = \"/mnt/sda/sijiali/DataSet/Harvard-GF/Dataset/Test\",\n",
    "    \n",
    "    # visualization\n",
    "    batch_size    = 1,                                         # 可视化取 1 即可\n",
    "    num_workers   = 2,                                         # DataLoader 线程数\n",
    "    n_components  = 3,                                         # PCA 分量数\n",
    "    save_root     = \"./Results_visualization/SALSA_multi/_vis_exports_cn\"      # 输出目录\n",
    ")\n",
    "\n",
    "# 构建与训练一致的 transform\n",
    "mean = np.array([0.485, 0.456, 0.406])\n",
    "std  = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "if CFG[\"transform\"] == \"vit\":\n",
    "    base_transform = get_vit_transform(CFG[\"img_size\"])\n",
    "elif CFG[\"transform\"] == \"cnn\":\n",
    "    base_transform = get_cnn_transform(CFG[\"img_size\"], mean, std)\n",
    "elif CFG[\"transform\"] == \"albumentations\":\n",
    "    base_transform = get_albumentations_transform(CFG[\"img_size\"])\n",
    "elif CFG[\"transform\"] == \"none\":\n",
    "    base_transform = None\n",
    "elif CFG[\"transform\"] == \"imagenet\":\n",
    "    base_transform = get_imagenet_transform(CFG[\"img_size\"], with_slab=(CFG[\"modality_type\"]=='rnflt+slab'))\n",
    "else:\n",
    "    raise ValueError(\"未知的 transform: %s\" % CFG[\"transform\"])\n",
    "\n",
    "os.makedirs(CFG[\"save_root\"], exist_ok=True)\n",
    "print(\"配置完成。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb638ae",
   "metadata": {},
   "source": [
    "## 1. 通用工具函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84c66da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def imshow_gray(img2d, title=None):\n",
    "    \"\"\"显示灰度图，img2d: H x W\"\"\"\n",
    "    plt.figure(figsize=(4,4))\n",
    "    plt.imshow(img2d, cmap=\"gray\")\n",
    "    if title: plt.title(title)\n",
    "    plt.axis(\"off\"); plt.show()\n",
    "\n",
    "def save_pca_maps(pil_image: Image.Image, pca_img: np.ndarray, save_dir: str,\n",
    "                  save_prefix: str, last_components_rgb: bool = True, resize=True):\n",
    "    \"\"\"\n",
    "    保存 PCA 热图：每个分量单独保存为灰度图，最后 3 个分量组合为 RGB。\n",
    "    pca_img: [Ht, Wt, C]\n",
    "    \"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    pil_image.save(os.path.join(save_dir, f\"{save_prefix}_orig_img.png\"))\n",
    "\n",
    "    Ht, Wt, C = pca_img.shape\n",
    "    for i in range(C):\n",
    "        comp = pca_img[:, :, i]\n",
    "        # 单图 min-max 归一化\n",
    "        comp = (comp - comp.min()) / (comp.max() - comp.min() + 1e-8)\n",
    "        im = Image.fromarray((comp * 255).astype(np.uint8))\n",
    "        if resize:\n",
    "            im = im.resize(pil_image.size, resample=Image.NEAREST).filter(ImageFilter.SHARPEN)\n",
    "        im.save(os.path.join(save_dir, f\"{save_prefix}_{i}.png\"))\n",
    "\n",
    "    if last_components_rgb and C >= 3:\n",
    "        comp = pca_img[:, :, -3:]\n",
    "        comp = (comp - comp.min(axis=(0,1), keepdims=True)) / (comp.ptp(axis=(0,1), keepdims=True) + 1e-8)\n",
    "        im = Image.fromarray((comp * 255).astype(np.uint8))\n",
    "        if resize:\n",
    "            im = im.resize(pil_image.size, resample=Image.NEAREST).filter(ImageFilter.SHARPEN)\n",
    "        im.save(os.path.join(save_dir, f\"{save_prefix}_{C-3}_{C-2}_{C-1}_rgb.png\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01761821",
   "metadata": {},
   "source": [
    "## 2. 融合层可解释性（gated-sum / attn）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ef2a39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@torch.no_grad()\n",
    "def get_branch_features(model, rnflt, slab):\n",
    "    \"\"\"提取两路全局特征 fr/fs（与你模型 forward 一致的骨干输出）。\"\"\"\n",
    "    fr = model.backbone_r(rnflt.to(device))\n",
    "    fs = model.backbone_s(slab.to(device))\n",
    "    return fr, fs  # [B,Dr], [B,Ds]\n",
    "\n",
    "@torch.no_grad()\n",
    "def fusion_introspect(model, fr, fs):\n",
    "    \"\"\"\n",
    "    外部重现融合头的关键量：\n",
    "    - gated-sum: 计算门控 g 以及融合后的向量\n",
    "    - attn     : 计算 2x2 跨模态注意力矩阵\n",
    "    其他 fusion（concat/sum）则给出 merge 前的表示（用于对比）。\n",
    "    \"\"\"\n",
    "    head = model.head\n",
    "    info = {}\n",
    "\n",
    "    # 特征维度对齐\n",
    "    proj_r = head.proj_r if hasattr(head, \"proj_r\") else nn.Identity()\n",
    "    proj_s = head.proj_s if hasattr(head, \"proj_s\") else nn.Identity()\n",
    "    fr_p = proj_r(fr); fs_p = proj_s(fs)\n",
    "\n",
    "    if getattr(head, \"fusion\", \"\") == \"gated-sum\":\n",
    "        cat = torch.cat([fr, fs], dim=1)      # [B,Dr+Ds]\n",
    "        g = head.gate(cat)                    # [B,1]，已 sigmoid\n",
    "        fused = g * fr_p + (1.0 - g) * fs_p   # [B,C]\n",
    "        info[\"g\"] = g.detach().cpu().numpy()\n",
    "        info[\"fused\"] = fused.detach().cpu().numpy()\n",
    "        info[\"fr_p\"] = fr_p.detach().cpu().numpy()\n",
    "        info[\"fs_p\"] = fs_p.detach().cpu().numpy()\n",
    "\n",
    "    elif getattr(head, \"fusion\", \"\") == \"attn\":\n",
    "        tokens = torch.stack([fr_p, fs_p], dim=1)   # [B,2,C]\n",
    "        Q = head.q(tokens); K = head.k(tokens); V = head.v(tokens)\n",
    "        attn = torch.softmax((Q @ K.transpose(-2, -1)) / (Q.shape[-1] ** 0.5), dim=-1)  # [B,2,2]\n",
    "        fused = (attn @ V).mean(dim=1)              # [B,C]\n",
    "        info[\"attn_2x2\"] = attn.detach().cpu().numpy()\n",
    "        info[\"fused\"] = fused.detach().cpu().numpy()\n",
    "\n",
    "    elif getattr(head, \"fusion\", \"\") in [\"concat\", \"sum\"]:\n",
    "        x = torch.cat([fr, fs], dim=1) if head.fusion == \"concat\" else (fr_p + fs_p)\n",
    "        info[\"pre_merge\"] = x.detach().cpu().numpy()\n",
    "\n",
    "    return info\n",
    "\n",
    "def plot_g_hist(g_values, title=\"门控 g 分布\"):\n",
    "    g_values = np.asarray(g_values).reshape(-1)\n",
    "    plt.figure(figsize=(4,3))\n",
    "    plt.hist(g_values, bins=30)\n",
    "    plt.title(title); plt.xlabel(\"g\"); plt.ylabel(\"数量\"); plt.show()\n",
    "\n",
    "def show_attn_matrix(attn_2x2, title=\"融合头 2x2 注意力矩阵\"):\n",
    "    A = np.asarray(attn_2x2)[0]  # 仅显示 batch=1 的情况\n",
    "    fig, ax = plt.subplots(figsize=(3,3))\n",
    "    im = ax.imshow(A, vmin=0, vmax=1)\n",
    "    ax.set_xticks([0,1]); ax.set_xticklabels([\"rnflt\",\"slab\"])\n",
    "    ax.set_yticks([0,1]); ax.set_yticklabels([\"rnflt\",\"slab\"])\n",
    "    ax.set_title(title); plt.colorbar(im); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fdb034",
   "metadata": {},
   "source": [
    "## 3. 骨干（ViT）可解释性：Attention Rollout / CLS→patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0b00fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 稳健零侵入适配器（兼容 sdpa / eager）=====\n",
    "import math, torch\n",
    "import torch.nn.functional as F\n",
    "from contextlib import contextmanager\n",
    "\n",
    "@contextmanager\n",
    "def _enable_outputs(hf_model, attn=True, hidd=True):\n",
    "    \"\"\"\n",
    "    临时打开 output_attentions / output_hidden_states；如当前是 sdpa，则尽力切到 eager。\n",
    "    若切换失败，则关闭 attentions（后续自动用 hidden-states 兜底），保证不报错。\n",
    "    \"\"\"\n",
    "    cfg = getattr(hf_model, \"config\", None)\n",
    "    state = {\"attn_ok\": False}  # 是否安全地启用了 attentions\n",
    "\n",
    "    # 记录原状态\n",
    "    orig_attn = getattr(cfg, \"output_attentions\", False) if cfg else False\n",
    "    orig_hidd = getattr(cfg, \"output_hidden_states\", False) if cfg else False\n",
    "    # 记录原注意力实现（模型或 config 可能持有）\n",
    "    orig_impl_model = getattr(hf_model, \"_attn_implementation\", None)\n",
    "    orig_impl_cfg   = getattr(cfg, \"_attn_implementation\", None) if cfg else None\n",
    "    orig_impl_cfg2  = getattr(cfg, \"attn_implementation\", None) if cfg else None\n",
    "\n",
    "    try:\n",
    "        # 先开 hidden states（这个不会和 sdpa 冲突）\n",
    "        if cfg and hidd:\n",
    "            cfg.output_hidden_states = True\n",
    "\n",
    "        # 试图启用 attentions\n",
    "        if attn and cfg:\n",
    "            # 先把实现切到 eager（优先用官方入口）\n",
    "            switched = False\n",
    "            if hasattr(hf_model, \"set_attn_implementation\"):\n",
    "                try:\n",
    "                    hf_model.set_attn_implementation(\"eager\")\n",
    "                    switched = True\n",
    "                except Exception:\n",
    "                    switched = False\n",
    "            # 若没有入口则尝试直接改 config（有些模型读 config）\n",
    "            if not switched and cfg is not None:\n",
    "                try:\n",
    "                    if hasattr(cfg, \"_attn_implementation\"):\n",
    "                        cfg._attn_implementation = \"eager\"\n",
    "                        switched = True\n",
    "                    if hasattr(cfg, \"attn_implementation\"):\n",
    "                        cfg.attn_implementation = \"eager\"\n",
    "                        switched = True\n",
    "                except Exception:\n",
    "                    switched = False\n",
    "\n",
    "            # 切换实现成功后再打开 attentions；否则让它保持 False，后续走兜底\n",
    "            if switched:\n",
    "                cfg.output_attentions = True\n",
    "                state[\"attn_ok\"] = True\n",
    "            else:\n",
    "                # 保证不触发 sdpa 的限制\n",
    "                if hasattr(cfg, \"output_attentions\"):\n",
    "                    cfg.output_attentions = False\n",
    "                state[\"attn_ok\"] = False\n",
    "\n",
    "        yield state\n",
    "\n",
    "    finally:\n",
    "        # 恢复实现\n",
    "        try:\n",
    "            if hasattr(hf_model, \"set_attn_implementation\") and orig_impl_model is not None:\n",
    "                hf_model.set_attn_implementation(orig_impl_model)\n",
    "        except Exception:\n",
    "            pass\n",
    "        # 恢复 config 中实现字段\n",
    "        if cfg is not None:\n",
    "            try:\n",
    "                if orig_impl_cfg is not None and hasattr(cfg, \"_attn_implementation\"):\n",
    "                    cfg._attn_implementation = orig_impl_cfg\n",
    "                if orig_impl_cfg2 is not None and hasattr(cfg, \"attn_implementation\"):\n",
    "                    cfg.attn_implementation  = orig_impl_cfg2\n",
    "            except Exception:\n",
    "                pass\n",
    "            # 恢复输出开关\n",
    "            cfg.output_attentions     = orig_attn\n",
    "            cfg.output_hidden_states  = orig_hidd\n",
    "\n",
    "\n",
    "def _get_reg(backbone):\n",
    "    \"\"\"读取 DINOv3 的 register token 数（没有则为 0）。\"\"\"\n",
    "    return int(getattr(backbone.net.config, \"num_register_tokens\", 0))\n",
    "\n",
    "def _maybe_norm(backbone, x):\n",
    "    \"\"\"与训练 forward 对齐：仅在 apply_imagenet_norm=True 时做归一化。\"\"\"\n",
    "    if getattr(backbone, \"apply_imagenet_norm\", False):\n",
    "        return backbone._imagenet_norm(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c93f4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 同名：ViT 多层注意力 Rollout（自动兼容 sdpa / 无注意力兜底）=====\n",
    "from typing import Union\n",
    "\n",
    "@torch.no_grad()\n",
    "def vit_attention_rollout(\n",
    "    backbone, x: torch.Tensor,\n",
    "    layers: Union[str, list[int]] = \"lastk:6\",   # \"all\" / \"lastk:6\" / [层索引...]\n",
    "    head_fuse: str = \"mean\",                     # \"mean\" / \"max\"\n",
    "    add_residual: bool = True,\n",
    "    residual_alpha: float = 0.5,\n",
    "    upsample_to_input: bool = True,\n",
    "    return_grid: bool = False,\n",
    "    eps: float = 1e-8\n",
    "):\n",
    "    assert not getattr(backbone, \"is_convnext\", False), \"此可视化仅适用于 ViT 分支（ConvNeXt 不支持）。\"\n",
    "\n",
    "    x = _maybe_norm(backbone, x)\n",
    "    B, H_in, W_in = x.shape[0], x.shape[-2], x.shape[-1]\n",
    "\n",
    "    with _enable_outputs(backbone.net, attn=True, hidd=True) as st:\n",
    "        out = backbone.net(\n",
    "            pixel_values=x,\n",
    "            output_attentions=bool(st[\"attn_ok\"]),\n",
    "            output_hidden_states=True,\n",
    "            return_dict=True\n",
    "        )\n",
    "        atts = out.attentions if st[\"attn_ok\"] else None\n",
    "\n",
    "        if atts is None:\n",
    "            # 兜底：最后一层 patch token 的 L2 范数\n",
    "            reg = _get_reg(backbone)\n",
    "            hs = out.hidden_states[-1]        # [B, T, D]\n",
    "            patch = hs[:, 1+reg:, :]          # [B, N, D]\n",
    "            score = patch.norm(dim=-1)        # [B, N]\n",
    "            N = score.shape[-1]; S = int(math.sqrt(N)); assert S*S == N, f\"N={N} 不是方形网格\"\n",
    "            M = score.view(B,1,S,S)\n",
    "            M = (M - M.amin((-2,-1),True)) / (M.amax((-2,-1),True)-M.amin((-2,-1),True)+eps)\n",
    "            if upsample_to_input:\n",
    "                M = F.interpolate(M, size=(H_in, W_in), mode=\"bilinear\", align_corners=False)\n",
    "            return M if not return_grid else (M, score.view(B,1,S,S))\n",
    "\n",
    "        # 选择层\n",
    "        if isinstance(layers, str):\n",
    "            if layers == \"all\":\n",
    "                use = range(len(atts))\n",
    "            elif layers.startswith(\"lastk:\"):\n",
    "                k = int(layers.split(\":\")[1]); use = range(len(atts)-k, len(atts))\n",
    "            else:\n",
    "                raise ValueError(\"layers 仅支持 'all' / 'lastk:K' / [list]\")\n",
    "        else:\n",
    "            use = layers\n",
    "\n",
    "        A_roll = None\n",
    "        for li in use:\n",
    "            A = atts[li]                      # [B, heads, T, T]\n",
    "            if head_fuse == \"mean\":\n",
    "                A = A.mean(dim=1)             # [B, T, T]\n",
    "            elif head_fuse == \"max\":\n",
    "                A, _ = A.max(dim=1)\n",
    "            else:\n",
    "                raise ValueError(\"head_fuse 仅支持 mean/max\")\n",
    "            A = A / (A.sum(dim=-1, keepdim=True) + eps)\n",
    "            if add_residual:\n",
    "                I = torch.eye(A.shape[-1], device=A.device, dtype=A.dtype).unsqueeze(0)\n",
    "                A = (A + residual_alpha * I) / (1.0 + residual_alpha)\n",
    "            A_roll = A if A_roll is None else A_roll @ A\n",
    "\n",
    "        reg = _get_reg(backbone)\n",
    "        cls_to_patch = A_roll[:, 0, 1+reg:]  # [B, N_patch]\n",
    "        N = cls_to_patch.shape[-1]; S = int(math.sqrt(N)); assert S*S == N, f\"N={N} 不是方形网格\"\n",
    "        M = cls_to_patch.view(B,1,S,S)\n",
    "        M = (M - M.amin((-2,-1),True)) / (M.amax((-2,-1),True)-M.amin((-2,-1),True)+eps)\n",
    "\n",
    "        if upsample_to_input:\n",
    "            M_up = F.interpolate(M, size=(H_in, W_in), mode=\"bilinear\", align_corners=False)\n",
    "            return M_up if not return_grid else (M_up, M)\n",
    "        return M\n",
    "\n",
    "\n",
    "# ===== 同名：最后一层 CLS→patch 显著图（自动兼容 sdpa / 无注意力兜底）=====\n",
    "@torch.no_grad()\n",
    "def vit_cls_saliency(\n",
    "    backbone, x: torch.Tensor,\n",
    "    head_fuse: str = \"mean\",          # \"mean\" / \"max\"\n",
    "    upsample_to_input: bool = True,\n",
    "    return_grid: bool = False,\n",
    "    eps: float = 1e-8\n",
    "):\n",
    "    assert not getattr(backbone, \"is_convnext\", False), \"此可视化仅适用于 ViT 分支。\"\n",
    "\n",
    "    x = _maybe_norm(backbone, x)\n",
    "    B, H_in, W_in = x.shape[0], x.shape[-2], x.shape[-1]\n",
    "\n",
    "    with _enable_outputs(backbone.net, attn=True, hidd=True) as st:\n",
    "        out = backbone.net(\n",
    "            pixel_values=x,\n",
    "            output_attentions=bool(st[\"attn_ok\"]),\n",
    "            output_hidden_states=True,\n",
    "            return_dict=True\n",
    "        )\n",
    "        reg = _get_reg(backbone)\n",
    "\n",
    "        if not st[\"attn_ok\"] or out.attentions is None:\n",
    "            # 兜底：CLS 与 patch 的余弦相似度\n",
    "            hs = out.hidden_states[-1]           # [B, T, D]\n",
    "            cls = F.normalize(hs[:, 0:1, :], dim=-1)\n",
    "            patch = F.normalize(hs[:, 1+reg:, :], dim=-1)\n",
    "            score = (patch * cls).sum(dim=-1)    # [B, N]\n",
    "            N = score.shape[-1]; S = int(math.sqrt(N)); assert S*S == N\n",
    "            M = score.view(B,1,S,S)\n",
    "            M = (M - M.amin((-2,-1),True)) / (M.amax((-2,-1),True)-M.amin((-2,-1),True)+eps)\n",
    "            if upsample_to_input:\n",
    "                M = F.interpolate(M, size=(H_in, W_in), mode=\"bilinear\", align_corners=False)\n",
    "            return M if not return_grid else (M, score.view(B,1,S,S))\n",
    "\n",
    "        # 正常分支：最后一层注意力\n",
    "        att = out.attentions[-1]                 # [B, heads, T, T]\n",
    "        if head_fuse == \"mean\":\n",
    "            A = att.mean(dim=1)\n",
    "        elif head_fuse == \"max\":\n",
    "            A, _ = att.max(dim=1)\n",
    "        else:\n",
    "            raise ValueError(\"head_fuse 仅支持 mean/max\")\n",
    "        A = A / (A.sum(dim=-1, keepdim=True) + eps)\n",
    "\n",
    "        cls_to_patch = A[:, 0, 1+reg:]          # [B, N]\n",
    "        N = cls_to_patch.shape[-1]; S = int(math.sqrt(N)); assert S*S == N\n",
    "        M = cls_to_patch.view(B,1,S,S)\n",
    "        M = (M - M.amin((-2,-1),True)) / (M.amax((-2,-1),True)-M.amin((-2,-1),True)+eps)\n",
    "\n",
    "        if upsample_to_input:\n",
    "            M_up = F.interpolate(M, size=(H_in, W_in), mode=\"bilinear\", align_corners=False)\n",
    "            return M_up if not return_grid else (M_up, M)\n",
    "        return M\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe8bdf1",
   "metadata": {},
   "source": [
    "## 4. Patch 级 PCA（共享 PCA 空间）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62b0846c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@torch.no_grad()\n",
    "def extract_patch_tokens(backbone, x: torch.Tensor, layer_idx: int = -1):\n",
    "    \"\"\"\n",
    "    提取指定层的 patch tokens（去掉 CLS 和可选的 register），返回 tokens[B,N,D] 以及网格大小 (Ht, Wt)。\n",
    "    \"\"\"\n",
    "    if getattr(backbone, \"apply_imagenet_norm\", False):\n",
    "        x = backbone._imagenet_norm(x)\n",
    "    out = backbone.net(pixel_values=x, output_hidden_states=True, return_dict=True)\n",
    "    hs = out.hidden_states[layer_idx]              # [B, T, D]\n",
    "    reg = int(getattr(backbone.net.config, \"num_register_tokens\", 0))\n",
    "    tokens = hs[:, 1+reg:, :]                      # [B, N, D] 去 CLS(+register)\n",
    "    B, N, D = tokens.shape\n",
    "    S = int(math.sqrt(N)); assert S*S == N, f\"patch 网格不是方形：N={N}\"\n",
    "    return tokens, S, S\n",
    "\n",
    "def tokens_to_pca_maps(tokens_list, grids, n_components=3, pca_fit=None):\n",
    "    \"\"\"\n",
    "    将若干样本/模态的 patch tokens 合并拟合一个 PCA（共享空间），\n",
    "    然后分别 transform 成各自的 PCA 热图 [Ht, Wt, C]。\n",
    "    \"\"\"\n",
    "    mats = [t.reshape(-1, t.shape[-1]) for t in tokens_list]   # [Ni, D]\n",
    "    X = np.concatenate([m.cpu().numpy() for m in mats], axis=0)\n",
    "    pca = pca_fit or PCA(n_components=n_components).fit(X)\n",
    "\n",
    "    outs = []\n",
    "    for t, (Ht,Wt) in zip(tokens_list, grids):\n",
    "        Z = pca.transform(t.reshape(-1, t.shape[-1]).cpu().numpy())  # [N, C]\n",
    "        Z = Z.reshape(Ht, Wt, n_components)\n",
    "        outs.append(Z)\n",
    "    return pca, outs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e23e79",
   "metadata": {},
   "source": [
    "## 5. 数据与模型加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e7896f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "验证集长度： 696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已加载权重： /mnt/sda/sijiali/GlaucomaCode/Results_SALSA_multi/dinov3/dinov3_imagenet_all_cls_concat_lr5e-5/ckpts/best_model_epoch_302_rmse_1.0466.pth\n",
      "缺失键： 0  额外键： 0\n",
      "模型就绪。\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 5.1 构建验证 DataLoader（仅用于可视化，不训练）\n",
    "try:\n",
    "    val_loader = get_dataloader_Salsa(\n",
    "        image_root=CFG[\"data_root\"],\n",
    "        hgf_test_root=CFG[\"hgf_test_root\"],\n",
    "        modality_type=CFG[\"modality_type\"],\n",
    "        batch_size=CFG[\"batch_size\"],\n",
    "        shuffle=False,\n",
    "        num_workers=CFG[\"num_workers\"],\n",
    "        transform=base_transform,\n",
    "        ids=None,   # 可指定子集ID列表；None 表示全量\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(\"get_dataloader_Salsa 导入失败，回退到直接实例化 Dataset：\", e)\n",
    "    ds = SalsaHGFAlignedDataset(\n",
    "        image_root=CFG[\"data_root\"],\n",
    "        hgf_test_root=CFG[\"hgf_test_root\"],\n",
    "        modality_type=CFG[\"modality_type\"],\n",
    "        transform=base_transform\n",
    "    )\n",
    "    val_loader = DataLoader(ds, batch_size=CFG[\"batch_size\"], shuffle=False, num_workers=CFG[\"num_workers\"], pin_memory=True)\n",
    "\n",
    "print(\"验证集长度：\", len(val_loader))\n",
    "\n",
    "# 5.2 构建模型并加载权重\n",
    "model = DualDinoV3LateFusion52(\n",
    "    rnflt_model_name=CFG[\"dinov3_model\"],\n",
    "    rnflt_vit_pool=CFG[\"vit_pool\"],\n",
    "    slab_model_name=CFG[\"dinov3_model\"],\n",
    "    slab_vit_pool=CFG[\"vit_pool\"],\n",
    "    fusion=CFG[\"fusion\"],\n",
    "    head_hidden_dim=512,\n",
    "    head_dropout=0.1,\n",
    "    out_dim=52,\n",
    ").to(device)\n",
    "\n",
    "def set_train_scope(m, scope=\"head\"):\n",
    "    \"\"\"与训练保持一致：仅用于控制是否冻结参数（不影响可视化）。\"\"\"\n",
    "    if scope == \"head\":\n",
    "        for p in m.parameters():\n",
    "            p.requires_grad = False\n",
    "        for p in m.head.parameters():\n",
    "            p.requires_grad = True\n",
    "    elif scope == \"all\":\n",
    "        for p in m.parameters():\n",
    "            p.requires_grad = True\n",
    "    else:\n",
    "        raise ValueError(\"未知的 train_scope\")\n",
    "\n",
    "set_train_scope(model, CFG[\"train_scope\"])\n",
    "\n",
    "def load_ckpt_safely(m, path):\n",
    "    \"\"\"兼容 DataParallel 前缀的稳健加载。\"\"\"\n",
    "    if path and os.path.exists(path):\n",
    "        sd = torch.load(path, map_location=\"cpu\")\n",
    "        if isinstance(sd, dict) and \"state_dict\" in sd:\n",
    "            sd = sd[\"state_dict\"]\n",
    "        new_sd = {}\n",
    "        for k,v in sd.items():\n",
    "            nk = k[7:] if k.startswith(\"module.\") else k\n",
    "            new_sd[nk] = v\n",
    "        missing, unexpected = m.load_state_dict(new_sd, strict=False)\n",
    "        print(\"已加载权重：\", path)\n",
    "        print(\"缺失键：\", len(missing), \" 额外键：\", len(unexpected))\n",
    "    else:\n",
    "        print(\"未加载权重，请在 CFG['ckpt_path'] 中填写权重路径。\")\n",
    "\n",
    "load_ckpt_safely(model, CFG[\"ckpt_path\"])\n",
    "model.eval()\n",
    "print(\"模型就绪。\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dca7c0f",
   "metadata": {},
   "source": [
    "## 6. 端到端示例：对一个样本生成三类可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f09c86f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:tornado.general:SEND Error: Host unreachable\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 取一个 batch\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m sid \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m, [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munknown\u001b[39m\u001b[38;5;124m\"\u001b[39m])[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m样本 ID：\u001b[39m\u001b[38;5;124m\"\u001b[39m, sid)\n",
      "File \u001b[0;32m/mnt/sda/sijiali/anaconda3/envs/glaucoma/lib/python3.9/site-packages/torch/utils/data/dataloader.py:708\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 708\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    712\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    713\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    714\u001b[0m ):\n",
      "File \u001b[0;32m/mnt/sda/sijiali/anaconda3/envs/glaucoma/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1458\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1455\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1457\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1458\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1459\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1461\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/sda/sijiali/anaconda3/envs/glaucoma/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1410\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1408\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m   1409\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_thread\u001b[38;5;241m.\u001b[39mis_alive():\n\u001b[0;32m-> 1410\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1411\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1412\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/mnt/sda/sijiali/anaconda3/envs/glaucoma/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1251\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1239\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1240\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1248\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1249\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1250\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1251\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1252\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1253\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1254\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1255\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1256\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/sda/sijiali/anaconda3/envs/glaucoma/lib/python3.9/queue.py:180\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m remaining \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[1;32m    179\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[0;32m--> 180\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_empty\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get()\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnot_full\u001b[38;5;241m.\u001b[39mnotify()\n",
      "File \u001b[0;32m/mnt/sda/sijiali/anaconda3/envs/glaucoma/lib/python3.9/threading.py:316\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 316\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    318\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 取一个 batch\n",
    "batch = next(iter(val_loader))\n",
    "sid = batch.get(\"id\", [\"unknown\"])[0]\n",
    "print(\"样本 ID：\", sid)\n",
    "\n",
    "# 从 batch 中取出 rnflt / slab（与你 transform 的输出键一致）\n",
    "x_r = batch.get(\"image\")   # [B,3,H,W]，你的 Dataset 中 key 为 'image'\n",
    "x_s = batch.get(\"slab\") if \"slab\" in batch else None\n",
    "\n",
    "if x_s is None and CFG[\"modality_type\"] == \"rnflt+slab\":\n",
    "    raise RuntimeError(\"期望 batch 中存在 'slab' 键，请检查 transform / 数据管线。\")\n",
    "\n",
    "x_r = x_r.to(device).float()\n",
    "x_s = x_s.to(device).float() if x_s is not None else None\n",
    "\n",
    "# ========== 6.1 融合层可解释性 ==========\n",
    "fr = model.backbone_r(x_r)\n",
    "fs = model.backbone_s(x_s) if x_s is not None else torch.zeros_like(fr)\n",
    "info = fusion_introspect(model, fr, fs)\n",
    "if \"g\" in info:\n",
    "    print(\"g 示例：\", info[\"g\"].ravel()[:5])\n",
    "    plot_g_hist(info[\"g\"], title=f\"门控 g（{sid}）\")\n",
    "if \"attn_2x2\" in info:\n",
    "    show_attn_matrix(info[\"attn_2x2\"], title=f\"融合 2x2 注意力（{sid}）\")\n",
    "\n",
    "# ========== 6.2 骨干（ViT）可解释性 ==========\n",
    "rollout_r = vit_attention_rollout(model.backbone_r, x_r)\n",
    "imshow_gray(rollout_r[0,0].detach().cpu().numpy(), f\"RNFLT rollout（{sid}）\")\n",
    "if x_s is not None:\n",
    "    rollout_s = vit_attention_rollout(model.backbone_s, x_s)\n",
    "    imshow_gray(rollout_s[0,0].detach().cpu().numpy(), f\"SLAB rollout（{sid}）\")\n",
    "\n",
    "# ========== 6.3 Patch 级 PCA（共享空间） ==========\n",
    "tok_r, Hr, Wr = extract_patch_tokens(model.backbone_r, x_r, layer_idx=-1)\n",
    "tokens_list = [tok_r.squeeze(0)]\n",
    "grids = [(Hr,Wr)]\n",
    "if x_s is not None:\n",
    "    tok_s, Hs, Ws = extract_patch_tokens(model.backbone_s, x_s, layer_idx=-1)\n",
    "    tokens_list.append(tok_s.squeeze(0))\n",
    "    grids.append((Hs,Ws))\n",
    "\n",
    "pca, Zs = tokens_to_pca_maps(tokens_list=tokens_list, grids=grids, n_components=CFG[\"n_components\"])\n",
    "\n",
    "# 保存到磁盘（使用 batch 里的图重建一个 PIL，仅用于预览与对齐尺寸）\n",
    "os.makedirs(os.path.join(CFG[\"save_root\"], \"rnflt\"), exist_ok=True)\n",
    "rnflt_np = x_r[0].detach().cpu().permute(1,2,0).numpy()\n",
    "rnflt_np = (rnflt_np - rnflt_np.min()) / (rnflt_np.max() - rnflt_np.min() + 1e-8)\n",
    "rnflt_pil = Image.fromarray((rnflt_np*255).astype(\"uint8\"))\n",
    "save_pca_maps(rnflt_pil, Zs[0], os.path.join(CFG[\"save_root\"], \"rnflt\"), save_prefix=str(sid))\n",
    "\n",
    "if x_s is not None:\n",
    "    os.makedirs(os.path.join(CFG[\"save_root\"], \"slab\"), exist_ok=True)\n",
    "    slab_np = x_s[0].detach().cpu().permute(1,2,0).numpy()\n",
    "    slab_np = (slab_np - slab_np.min()) / (slab_np.max() - slab_np.min() + 1e-8)\n",
    "    slab_pil = Image.fromarray((slab_np*255).astype(\"uint8\"))\n",
    "    save_pca_maps(slab_pil, Zs[1], os.path.join(CFG[\"save_root\"], \"slab\"), save_prefix=str(sid))\n",
    "\n",
    "print(\"PCA 热图已保存至：\", CFG[\"save_root\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b82f8f0",
   "metadata": {},
   "source": [
    "## 7. 整合可视化图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e16414e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "# =========================\n",
    "# 配置（按需修改）\n",
    "# =========================\n",
    "rnflt_dir = Path(\"./Results_visualization/SALSA_multi/_vis_exports_cn/rnflt\")  # 你的 rnflt PCA 目录\n",
    "slab_dir  = Path(\"./Results_visualization/SALSA_multi/_vis_exports_cn/slab\")   # 你的 slab  PCA 目录\n",
    "out_dir   = Path(\"./Results_visualization/SALSA_multi/_vis_exports_cn/panels\") # 面板输出目录\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 叠加可视化参数\n",
    "overlay_alpha_gray = 0.45   # comp0/1/2 灰度叠加透明度\n",
    "overlay_alpha_rgb  = 0.65   # RGB 合成叠加透明度\n",
    "rgb_overlay_as_gray = False # True 则把 RGB 合成转灰度后再叠加；False 保持彩色叠加\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be3a910",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =========================\n",
    "# 工具函数\n",
    "# =========================\n",
    "def _load_png(path, mode=None):\n",
    "    im = Image.open(path)\n",
    "    if mode is not None:\n",
    "        im = im.convert(mode)\n",
    "    return im\n",
    "\n",
    "def _paths_for_id_with_rgb(mod_dir, sid):\n",
    "    \"\"\"返回：原图、comp0/1/2、rgb合成 的路径\"\"\"\n",
    "    p_orig = mod_dir / f\"{sid}_orig_img.png\"\n",
    "    p0 = mod_dir / f\"{sid}_0.png\"\n",
    "    p1 = mod_dir / f\"{sid}_1.png\"\n",
    "    p2 = mod_dir / f\"{sid}_2.png\"\n",
    "    prgb = mod_dir / f\"{sid}_0_1_2_rgb.png\"\n",
    "    return p_orig, [p0, p1, p2], prgb\n",
    "\n",
    "def _collect_ids(rnflt_dir, slab_dir):\n",
    "    ids_r = {p.name.replace(\"_orig_img.png\", \"\") for p in rnflt_dir.glob(\"*_orig_img.png\")}\n",
    "    ids_s = {p.name.replace(\"_orig_img.png\", \"\") for p in slab_dir.glob(\"*_orig_img.png\")}\n",
    "    return sorted(list(ids_r & ids_s))\n",
    "\n",
    "def _resize_like(img, ref, resample=Image.NEAREST):\n",
    "    if img.size != ref.size:\n",
    "        return img.resize(ref.size, resample=resample)\n",
    "    return img\n",
    "\n",
    "def _overlay_colormap(base_pil, comp_gray_pil, alpha=0.5, cmap=\"jet\"):\n",
    "    \"\"\"把灰度 PCA component 渲染成伪彩色，然后叠加到 base 图上\"\"\"\n",
    "    comp_gray_pil = _resize_like(comp_gray_pil.convert(\"L\"), base_pil)\n",
    "    g = np.array(comp_gray_pil, dtype=np.float32)\n",
    "    g = (g - g.min()) / (g.max() - g.min() + 1e-8)  # normalize 0-1\n",
    "    rgba = cm.get_cmap(cmap)(g)  # (H,W,4)\n",
    "    rgb = (rgba[..., :3] * 255).astype(np.uint8)\n",
    "    comp_color = Image.fromarray(rgb, mode=\"RGB\")\n",
    "    return Image.blend(base_pil.convert(\"RGB\"), comp_color, alpha=alpha)\n",
    "\n",
    "def _overlay_rgb(orig_rgb_pil, rgb_pil, alpha=0.45, as_gray=False):\n",
    "    \"\"\"RGB 合成图叠加；as_gray=True 时先转灰度再叠加\"\"\"\n",
    "    rgb_pil = _resize_like(rgb_pil.convert(\"RGB\"), orig_rgb_pil)\n",
    "    if as_gray:\n",
    "        g = rgb_pil.convert(\"L\")\n",
    "        rgb_pil = Image.merge(\"RGB\", [g, g, g])\n",
    "    return Image.blend(orig_rgb_pil.convert(\"RGB\"), rgb_pil, alpha=alpha)\n",
    "\n",
    "def _to_gray_rgb(img_rgb_pil: Image.Image) -> Image.Image:\n",
    "    \"\"\"把彩色图转成3通道灰度（用于叠加的底图）。\"\"\"\n",
    "    g = img_rgb_pil.convert(\"L\")\n",
    "    return Image.merge(\"RGB\", [g, g, g])\n",
    "\n",
    "def make_panels_for_id(\n",
    "    sid, rnflt_dir, slab_dir, out_dir,\n",
    "    overlay_alpha_gray=0.45, overlay_alpha_rgb=0.45,\n",
    "    rgb_overlay_as_gray=False,        # True: RGB map -> gray before overlay\n",
    "    base_gray_overlays_rnflt=True,    # True: RNFLT overlay uses gray base\n",
    "    base_gray_overlays_slab=True,     # True: SLAB  overlay uses gray base\n",
    "    dpi=200,\n",
    "    cmap_comp=\"jet\"                   # colormap for PC overlays\n",
    "):\n",
    "    # ---------- paths ----------\n",
    "    r_orig_p, r_comp_ps, r_rgb_p = _paths_for_id_with_rgb(rnflt_dir, sid)\n",
    "    s_orig_p, s_comp_ps, s_rgb_p = _paths_for_id_with_rgb(slab_dir,  sid)\n",
    "\n",
    "    need = [r_orig_p, s_orig_p, r_rgb_p, s_rgb_p, *r_comp_ps, *s_comp_ps]\n",
    "    for p in need:\n",
    "        if not Path(p).exists():\n",
    "            print(f\"[WARN] missing file: {p}\")\n",
    "            return\n",
    "\n",
    "    # ---------- load ----------\n",
    "    r_orig = _load_png(r_orig_p, \"RGB\")\n",
    "    s_orig = _load_png(s_orig_p, \"RGB\")\n",
    "    r_comps = [_load_png(p, \"L\") for p in r_comp_ps]\n",
    "    s_comps = [_load_png(p, \"L\") for p in s_comp_ps]\n",
    "    r_rgb = _load_png(r_rgb_p, \"RGB\")\n",
    "    s_rgb = _load_png(s_rgb_p, \"RGB\")\n",
    "\n",
    "    # =========================================================\n",
    "    # Panel A (2×5): Image + PC0 + PC1 + PC2 + PC0/1/2 RGB\n",
    "    # =========================================================\n",
    "    figA, axA = plt.subplots(2, 5, figsize=(16, 7))\n",
    "    titlesA = [\"Image\", \"PC0\", \"PC1\", \"PC2\", \"PC0/1/2 RGB\"]\n",
    "\n",
    "    # RNFLT row\n",
    "    axA[0, 0].imshow(r_orig); axA[0, 0].set_title(f\"RNFLT {titlesA[0]}\"); axA[0, 0].axis(\"off\")\n",
    "    for j in range(3):\n",
    "        axA[0, j+1].imshow(r_comps[j], cmap=\"gray\", vmin=0, vmax=255)\n",
    "        axA[0, j+1].set_title(f\"RNFLT {titlesA[j+1]}\"); axA[0, j+1].axis(\"off\")\n",
    "    axA[0, 4].imshow(r_rgb); axA[0, 4].set_title(f\"RNFLT {titlesA[4]}\"); axA[0, 4].axis(\"off\")\n",
    "\n",
    "    # SLAB row\n",
    "    axA[1, 0].imshow(s_orig); axA[1, 0].set_title(f\"SLAB {titlesA[0]}\"); axA[1, 0].axis(\"off\")\n",
    "    for j in range(3):\n",
    "        axA[1, j+1].imshow(s_comps[j], cmap=\"gray\", vmin=0, vmax=255)\n",
    "        axA[1, j+1].set_title(f\"SLAB {titlesA[j+1]}\"); axA[1, j+1].axis(\"off\")\n",
    "    axA[1, 4].imshow(s_rgb); axA[1, 4].set_title(f\"SLAB {titlesA[4]}\"); axA[1, 4].axis(\"off\")\n",
    "\n",
    "    figA.suptitle(f\"{sid} — PCA Panel A: Image + PC0/1/2 + PC0/1/2 RGB\", fontsize=14, y=1.02)\n",
    "    # figA.tight_layout(rect=[0, 0, 1, 0.96])  # 预留顶部避免重叠\n",
    "    out_A = out_dir / f\"{sid}_panelA_2x5_image_pc012_rgb.png\"\n",
    "    figA.savefig(out_A, dpi=dpi, bbox_inches=\"tight\")\n",
    "    plt.close(figA)\n",
    "\n",
    "    # =========================================================\n",
    "    # Panel B (2×5): Image + PC0/1/2 overlay (colored) + RGB overlay\n",
    "    # =========================================================\n",
    "    # bases for overlay (gray base as requested)\n",
    "    r_base = _to_gray_rgb(r_orig) if base_gray_overlays_rnflt else r_orig\n",
    "    s_base = _to_gray_rgb(s_orig) if base_gray_overlays_slab  else s_orig\n",
    "\n",
    "    # colored overlays for PCs\n",
    "    r_over_comp = [_overlay_colormap(r_base, r_comps[j], alpha=overlay_alpha_gray, cmap=cmap_comp) for j in range(3)]\n",
    "    s_over_comp = [_overlay_colormap(s_base, s_comps[j], alpha=overlay_alpha_gray, cmap=cmap_comp) for j in range(3)]\n",
    "\n",
    "    # RGB overlay (can force gray map if wanted)\n",
    "    r_over_rgb  = _overlay_rgb(r_base, r_rgb, alpha=overlay_alpha_rgb, as_gray=rgb_overlay_as_gray)\n",
    "    s_over_rgb  = _overlay_rgb(s_base, s_rgb, alpha=overlay_alpha_rgb, as_gray=rgb_overlay_as_gray)\n",
    "\n",
    "    figB, axB = plt.subplots(2, 5, figsize=(18, 7))\n",
    "    titlesB = [\"Image\", \"PC0 overlay\", \"PC1 overlay\", \"PC2 overlay\", \"RGB overlay\"]\n",
    "\n",
    "    # RNFLT row\n",
    "    axB[0, 0].imshow(r_orig); axB[0, 0].set_title(f\"RNFLT {titlesB[0]}\"); axB[0, 0].axis(\"off\")\n",
    "    for j in range(3):\n",
    "        axB[0, j+1].imshow(r_over_comp[j]); axB[0, j+1].set_title(f\"RNFLT {titlesB[j+1]}\"); axB[0, j+1].axis(\"off\")\n",
    "    axB[0, 4].imshow(r_over_rgb); axB[0, 4].set_title(f\"RNFLT {titlesB[4]}\"); axB[0, 4].axis(\"off\")\n",
    "\n",
    "    # SLAB row\n",
    "    axB[1, 0].imshow(s_orig); axB[1, 0].set_title(f\"SLAB {titlesB[0]}\"); axB[1, 0].axis(\"off\")\n",
    "    for j in range(3):\n",
    "        axB[1, j+1].imshow(s_over_comp[j]); axB[1, j+1].set_title(f\"SLAB {titlesB[j+1]}\"); axB[1, j+1].axis(\"off\")\n",
    "    axB[1, 4].imshow(s_over_rgb); axB[1, 4].set_title(f\"SLAB {titlesB[4]}\"); axB[1, 4].axis(\"off\")\n",
    "\n",
    "    figB.suptitle(f\"{sid} — PCA Panel B: Image + PC overlays + RGB overlay\", fontsize=14, y=1.02)\n",
    "    figB.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    out_B = out_dir / f\"{sid}_panelB_2x5_image_pc_overlays_rgb.png\"\n",
    "    figB.savefig(out_B, dpi=dpi, bbox_inches=\"tight\")\n",
    "    plt.close(figB)\n",
    "\n",
    "    print(f\"[OK] saved: {out_A.name} | {out_B.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfad75f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 批量生成（对 rnflt/slab 都存在的 ID）\n",
    "# =========================\n",
    "ids = _collect_ids(rnflt_dir, slab_dir)\n",
    "print(f\"发现 {len(ids)} 个样本：\", ids[:5], \"...\" if len(ids) > 5 else \"\")\n",
    "\n",
    "for sid in ids:\n",
    "    make_panels_for_id(\n",
    "    sid=sid,\n",
    "    rnflt_dir=rnflt_dir,\n",
    "    slab_dir=slab_dir,\n",
    "    out_dir=out_dir,\n",
    "    overlay_alpha_gray=overlay_alpha_gray,   # 灰度热图叠加透明度\n",
    "    overlay_alpha_rgb=overlay_alpha_gray,    # RGB热图叠加透明度\n",
    "    rgb_overlay_as_gray=rgb_overlay_as_gray  # True→RGB热图先转灰度再叠加\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "glaucoma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
